{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Engineering - Findind lab of origin for various plasmids using Sequential Neural Network tuned via Bayesian Optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro- notes <br>\n",
    "Driven Data Competition\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "Usefullness -> allows better controle over who is doing what\n",
    "\n",
    "Topo function pad\n",
    "Topo Seq NN\n",
    "Topo Bayesian opt (link to giuthub)\n",
    "\n",
    "plot model ?\n",
    "\n",
    "mention voigt lab (without link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import \n",
    "df=pd.read_csv(r\"C:\\Users\\Utilisateur\\Desktop\\Challenge\\genetic_engineering\\train_values.csv\",index_col=0)\n",
    "Labels=pd.read_csv(r\"C:\\Users\\Utilisateur\\Desktop\\Challenge\\genetic_engineering\\train_labels.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"E D A \"\"\"\n",
    "#sequences\n",
    "Seq_length=pd.DataFrame(df.sequence.apply(len))\n",
    "Seq_length.hist(bins=100,figsize=(10,8))\n",
    "\n",
    "#lab\n",
    "Lab_id=pd.DataFrame(Labels.idxmax(axis=1),columns=['lab_id'])\n",
    "plasmid_per_lab=pd.DataFrame(Lab_id['lab_id'].value_counts().sort_values(ascending=False))\n",
    "plasmid_per_lab.columns=['plasmid_per_lab']\n",
    "plasmid_per_lab['Percentage']=plasmid_per_lab/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, Labels, test_size=0.2, random_state=1)\n",
    "#split train/val\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions\n",
    "\n",
    "### Padding function\n",
    "\n",
    "    As the input of the neural network ought to be vectors of the same size and since the plasmid sequences range from .... to ..., median value : , we have to pas the sequences, cad, define a threshold,shorten the sequences longer than this threshold and extend  with random nucleoids the shorter ones. That is what **pad_dna** is doing\n",
    "\n",
    "\n",
    "### One hot encoding\n",
    "\n",
    "    The base pare cannot be fed as raw inputs to the network, we therefore need to transform them into 1hot vectors, following the arbitrary convention : 'A':[1,0,0,0],'T':[0,1,0,0],'G':[0,0,1,0],'C':[0,0,0,1], 'N':[0,0,0,0]} where N is ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_dna(seqs,maxlen):\n",
    "    padded_seqs = [''] * len(seqs)\n",
    "    for i in seqs:\n",
    "        if len(i) > maxlen:\n",
    "            i = i[:maxlen]\n",
    "            maxlen = len(i)\n",
    "    for j in range(len(seqs)):\n",
    "        if len(seqs[j]) > maxlen:\n",
    "            seq = seqs[j][0:maxlen]\n",
    "        else:\n",
    "            seq = seqs[j]\n",
    "        padded_seqs[j] = seq + \"N\" * (maxlen - len(seq))\n",
    "    return padded_seqs\n",
    "\n",
    "def convert_onehot2D(list_of_seqs):\n",
    "    one_hot = np.zeros((len(list_of_seqs),4,len(list_of_seqs[0])))\n",
    "    nt_dict = {'A':[1,0,0,0],'T':[0,1,0,0],'G':[0,0,1,0],'C':[0,0,0,1], 'N':[0,0,0,0]}\n",
    "    count = 0\n",
    "    for seq in list_of_seqs:\n",
    "        if len(seq) > 1:\n",
    "            for letter in range(len(seq)):\n",
    "                for i in range(4):\n",
    "                    one_hot[count][i][letter] = (nt_dict[seq[letter]])[i]\n",
    "        count += 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "#encoding sequences\n",
    "\n",
    "max_len=500\n",
    "X_train_padded=pad_dna(x_train.sequence,max_len)\n",
    "X_val_padded=pad_dna(x_val.sequence,max_len)\n",
    "X_test_padded=pad_dna(x_test.sequence,max_len)\n",
    "\n",
    "#steady variables\n",
    "X_train=np.transpose(convert_onehot2D(X_train_padded), axes=(0,2,1))\n",
    "X_val=np.transpose(convert_onehot2D(X_val_padded), axes=(0,2,1))\n",
    "X_test=np.transpose(convert_onehot2D(X_test_padded), axes=(0,2,1))\n",
    "\n",
    "Y_train=y_train\n",
    "Y_val=y_val\n",
    "Y_test=y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization\n",
    "\n",
    "Package details on github [here](https://github.com/fmfn/BayesianOptimization)\n",
    "\n",
    "number of iterations\n",
    "parameters of iteration (number of neurones/ number of filter and length of filter.)\n",
    "monitoring (as target) : validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | filter... | filter... | num_de... |\n",
      "-------------------------------------------------------------\n",
      "4727/4727 [==============================] - 46s 10ms/step - loss: 5.5363 - top_k_categorical_accuracy: 0.3669 - val_loss: 4.8663 - val_top_k_categorical_accuracy: 0.4350\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.435   \u001b[0m | \u001b[0m 5.335   \u001b[0m | \u001b[0m 47.38   \u001b[0m | \u001b[0m 5.431   \u001b[0m |\n",
      "4727/4727 [==============================] - 71s 15ms/step - loss: 4.4017 - top_k_categorical_accuracy: 0.5280 - val_loss: 3.8178 - val_top_k_categorical_accuracy: 0.6148\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6148  \u001b[0m | \u001b[95m 15.75   \u001b[0m | \u001b[95m 492.1   \u001b[0m | \u001b[95m 185.7   \u001b[0m |\n",
      "4727/4727 [==============================] - 198s 42ms/step - loss: 4.3757 - top_k_categorical_accuracy: 0.5354 - val_loss: 3.7899 - val_top_k_categorical_accuracy: 0.6322\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.6322  \u001b[0m | \u001b[95m 4.81    \u001b[0m | \u001b[95m 412.6   \u001b[0m | \u001b[95m 465.5   \u001b[0m |\n",
      "4727/4727 [==============================] - 143s 30ms/step - loss: 4.4219 - top_k_categorical_accuracy: 0.5268 - val_loss: 3.8115 - val_top_k_categorical_accuracy: 0.6215\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6215  \u001b[0m | \u001b[0m 45.55   \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 392.1   \u001b[0m |\n",
      "4727/4727 [==============================] - 130s 27ms/step - loss: 4.6166 - top_k_categorical_accuracy: 0.4956 - val_loss: 3.9064 - val_top_k_categorical_accuracy: 0.5881\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5881  \u001b[0m | \u001b[0m 31.0    \u001b[0m | \u001b[0m 216.9   \u001b[0m | \u001b[0m 90.27   \u001b[0m |\n",
      "4727/4727 [==============================] - 168s 36ms/step - loss: 4.3875 - top_k_categorical_accuracy: 0.5335 - val_loss: 3.8066 - val_top_k_categorical_accuracy: 0.6223\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6223  \u001b[0m | \u001b[0m 5.279   \u001b[0m | \u001b[0m 410.5   \u001b[0m | \u001b[0m 467.8   \u001b[0m |\n",
      "4727/4727 [==============================] - 126s 27ms/step - loss: 4.3409 - top_k_categorical_accuracy: 0.5381 - val_loss: 3.7285 - val_top_k_categorical_accuracy: 0.6309\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6309  \u001b[0m | \u001b[0m 5.58    \u001b[0m | \u001b[0m 453.2   \u001b[0m | \u001b[0m 432.4   \u001b[0m |\n",
      "4727/4727 [==============================] - 180s 38ms/step - loss: 4.3790 - top_k_categorical_accuracy: 0.5340 - val_loss: 3.7833 - val_top_k_categorical_accuracy: 0.6271\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6271  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 395.8   \u001b[0m | \u001b[0m 406.4   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': 0.6321802735328674, 'params': {'filter_length': 4.809964199642451, 'filter_num': 412.6209157839004, 'num_dense_nodes': 465.48022810238274}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"                  B A Y E S I A N   -  O P T I M I Z A T I O N                \"\"\"\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import time\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model \n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "#network parameters:\n",
    "dna_bp_length=X_train.shape[1]\n",
    "num_classes=Y_train.shape[1]\n",
    "min_batch_size = 8\n",
    "\n",
    "def neural_network_target(num_dense_nodes,filter_num,filter_length):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(filters=int(filter_num),\n",
    "                            kernel_size=int(filter_num),\n",
    "                            activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=int(max_len-filter_num+1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=num_dense_nodes))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=num_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[tf.keras.metrics.TopKCategoricalAccuracy(10)])\n",
    "    checkpointer = ModelCheckpoint(filepath=\"checkpoint.hdf5\", monitor=\"val_acc\", mode='auto', verbose=1, \\\n",
    "                  save_best_only=True)  \n",
    "    early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, mode='auto', verbose=0)\n",
    "    \n",
    "    epoch=1\n",
    "    history = model.fit(X_train, Y_train, batch_size = min_batch_size,\n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        epochs=epoch, verbose=1)\n",
    "    \n",
    "    result=history.history['val_top_k_categorical_accuracy'][-1]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "gp_params = {\"alpha\": 1e-5, \"n_restarts_optimizer\": 2}\n",
    "bo = BayesianOptimization(neural_network_target,\n",
    "                          {'num_dense_nodes': (4,512),\n",
    "                           'filter_num': (1,500),\n",
    "                           'filter_length': (1,48)})\n",
    "\n",
    "bo.maximize(n_iter=3, acq=\"ucb\", kappa=5, **gp_params)\n",
    "\n",
    "\n",
    "print(bo.max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Neural Network\n",
    "\n",
    "info : \n",
    "use conv1D with ...parameters (extracted from bayesian optimization)\n",
    "batch normalization for ???\n",
    "Metrics (Top 10)-> tf.keras.metrics.TopKCategoricalAccuracy(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Neural Network\"\"\"\"\"\n",
    "\n",
    "#network parameters:\n",
    "dna_bp_length=X_train.shape[1]\n",
    "num_classes=Y_train.shape[1]\n",
    "# network hyperparameters\n",
    "filter_num = 130 \n",
    "filter_len = 46\n",
    "num_dense_nodes = 345 \n",
    "total_epoch = 100 \n",
    "min_batch_size = 8\n",
    "start = time.time()\n",
    "\n",
    "# model specification\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(filters=filter_num,\n",
    "                        kernel_size=filter_len,\n",
    "                        activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=max_len-filter_len+1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=num_dense_nodes))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.TopKCategoricalAccuracy(10)])\n",
    "checkpointer = ModelCheckpoint(filepath=\"checkpoint.hdf5\", monitor=\"val_acc\", mode='auto', verbose=1, \\\n",
    "              save_best_only=True)  \n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, mode='auto', verbose=1)\n",
    "\n",
    "epoch=10\n",
    "history = model.fit(X_train, Y_train, batch_size = min_batch_size,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    epochs=epoch, verbose=1)\n",
    "\n",
    "print(model.summary())\n",
    "    \n",
    "    \n",
    "net=history    \n",
    "#plot\n",
    "loss=net.history['loss']\n",
    "acc=net.history['top_k_categorical_accuracy']\n",
    "val_loss=net.history['val_loss']\n",
    "val_acc=net.history['val_top_k_categorical_accuracy']\n",
    "\n",
    "plt.plot(loss,label='loss')\n",
    "plt.plot(acc,label='accuracy')\n",
    "plt.plot(val_loss,label='val_loss')\n",
    "plt.plot(val_acc,label='val_accuracy')\n",
    "plt.hlines(1,  0,epoch, colors='k', linestyles='--')\n",
    "plt.legend()\n",
    "plt.title('CNN')\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "print('computational time for nn :',stop-start,  'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
